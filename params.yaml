chunker:
  chunk_size: # кол-вл токенов в чанке
  chunk_overlap: # на сколько один чанк залезает на другой
  raptor: # техника для работы с точечными вопросами и общего характера - чанк индексируется вместе с саммари кластера. Таким образом, обходится ограничение кнн
  summarize: True # саммаризация документов как аналог или дополнение к чанкингу 

vectorizer:
  transformer_model: # open-source модель 
  normalize embeddings: True # нормализация
  vector_size: # размерность
  colbert: # эмбеддинг для каждого токена, сравниваются эмбединги токенов вопроса и документа ! слишком большая задержка, но мб мы можем на уровне саммари кластера искать 

knn:
  n_neighbors: 3 # кол-во соседей
  use_nearest_centroids: True
  relevance_threshhold: # мин близость 
  cross_encoder: 

LLM:
  llm_model: # модель 
  prompt: # промпт на саммаризацию ответа из бакетов
  # также есть подход выбора промпта с помощью эмбеддеров (разные промпты для разных типов вопросов)

query_processing:
  rewording: True
  rewording_prompt: # просим переписать вопрос Х раз
  n_reworded_questions: # кол-во Х

  decomposition: False
  decomp_prompt: #define new prompt that answers a chain of sub questions to our question + considers the answers defined from previous questions)

  