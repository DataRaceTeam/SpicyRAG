project:
  name: "SpicyRag"

database:
  user: "user"
  password: "password"
  name: "spicyragdb"
  host: "localhost"
  port: 5432

logging:
  level: "INFO"

server:
  host: "0.0.0.0"
  port: 8000

llm:
  base_url: "${LLM_BASE_URL}"
  api_key: "${LLM_API_KEY}"
  model: "meta/llama-3.1-405b-instruct"
  role: "user"
  system_prompt: |
    Вы являетесь виртуальным юридическим консультантом, специализирующимся на анализе и интерпретации юридических документов и правовых норм.
    Ваша задача — помочь пользователю, используя предоставленный контекст, чтобы дать точный и обоснованный ответ на его юридический вопрос.
    Контекст может содержать выдержки из законов, нормативных актов, судебных решений, договоров или других юридических текстов.

    Инструкции:
      1. Внимательно проанализируй контекст и определите, какие части контекста наиболее релевантны, приводи всю полезную информацию из контекста
      2. Используй релевантные фрагменты контекста (не пиши к чему обращаешься, не упоминай пунктов) для создания полного и юридически обоснованного ответа. Приводи цитаты из контекста в соответствии
      3. После ответа напиши вывод о написанной тобой информации, начиная со слова Таким образом

    ВАЖНО: не упоминай, что ты работаешь с контекстом! Отвечай структурно и по пунктам.
  temperature: 0.15
  top_p: 0.7
  max_tokens: 10000

llm_rewriter:
  base_url: "${LLM_REWRITER_BASE_URL}"
  api_key: "${LLM_REWRITER_API_KEY}"
  model: "meta/llama-3.1-8b-instruct"
  role: "user"
  system_prompt: |
    Вы - полезный помощник, который генерирует несколько поисковых запросов на основе одного входного запроса.
    Выполните расширение запроса. Если существует несколько распространенных способов формулировки пользовательского вопроса или общих синонимов для ключевых слов в вопросе, обязательно верните несколько версий запроса с разными формулировками.
    Если в тексте есть сокращения или слова, которые вам незнакомы, не пытайтесь их перефразировать.
    Верните только 3 разных варианта вопроса.
  temperature: 0.2
  top_p: 0.7
  max_tokens: 1024

embedding_model:
  name: "paraphrase-MiniLM-L6-v2"
  dimension: 384

data_sources:
  excel_file: "./data/v2_ragas_npa_dataset_firstPart.xlsx"
  text_file: "./data/hmao_npa.txt"
  text_separator: "\n\n"

data_processing:
  chunker:
    py_class: interface.chunker.RecursiveCharacterTextSplitterChunker
    kwargs:
      chunk_size: 2048
      chunk_overlap: 128
      separators:
        - '\n#{1,6} '
        - '```\n'
        - '\n\\*\\*\\*+\n'
        - '\n---+\n'
        - '\n___+\n'
        - '\n\n'
        - '\n'
        - ' '
        - ''
        - ','
        - '|'
  top_k: 3
  similarity_threshold: 0.7